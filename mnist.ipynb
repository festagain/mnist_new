{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "output_path = \"mnist_train_images/\"\n",
    "train_path = \"mnist_train.csv\"\n",
    "test_path = \"mnist_test.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T14:01:24.349928395Z",
     "start_time": "2023-05-15T14:01:21.637749128Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:05:09.749136699Z",
     "start_time": "2023-05-15T17:05:09.741080521Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "def convert_dataset(train_path):\n",
    "    dataset = np.genfromtxt(train_path, delimiter=',', skip_header=1)\n",
    "    labels = dataset[:, 0].astype(np.uint8)\n",
    "    values = dataset[:, 1:].astype(np.uint8)\n",
    "    images = np.reshape(values, (-1, 28, 28))\n",
    "    return images, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:51:44.955583307Z",
     "start_time": "2023-05-15T17:51:44.942916198Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T17:52:08.956844523Z",
     "start_time": "2023-05-15T17:51:45.493772228Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = np.genfromtxt(\"mnist_train.csv\", delimiter=',', skip_header=1)\n",
    "# labels = dataset[:, 0].astype(np.uint8)\n",
    "# values = dataset[:,1:].astype(np.uint8)\n",
    "# images = np.reshape(values, (-1,28,28))\n",
    "# images.shape\n",
    "\n",
    "images, labels = convert_dataset(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T17:52:12.380857679Z",
     "start_time": "2023-05-15T17:52:08.956673597Z"
    }
   },
   "outputs": [],
   "source": [
    "test_images, test_labels = convert_dataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 200\n",
    "epochs = 10\n",
    "log_interval = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:52:12.383776709Z",
     "start_time": "2023-05-15T17:52:12.382619655Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:46:59.530791992Z",
     "start_time": "2023-05-15T17:46:59.520458191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_conv1, num_conv2, fc_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,num_conv1,kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(num_conv1, num_conv2,kernel_size=5,stride=1, padding=2)\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(6*6*num_conv2,fc_output)\n",
    "        self.fc2 = nn.Linear(fc_output, 10)\n",
    "        # self.fc1 = nn.Linear(28*28, 200)\n",
    "        # self.fc2 = nn.Linear(200, 200)\n",
    "        # self.fc3 = nn.Linear(200, 10)\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = out.reshape(x.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        # x = self.fc3(x)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:46:59.712869907Z",
     "start_time": "2023-05-15T17:46:59.702961221Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [
    {
     "data": {
      "text/plain": "Net(\n  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=2304, out_features=1000, bias=True)\n  (fc2): Linear(in_features=1000, out_features=10, bias=True)\n)"
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(num_conv1=32,num_conv2=64,fc_output=1000)\n",
    "net.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:47:00.410120374Z",
     "start_time": "2023-05-15T17:47:00.317250293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:54:02.424756296Z",
     "start_time": "2023-05-15T17:54:02.380419836Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [],
   "source": [
    "def rotate(image, label):\n",
    "        degree = random.randint(1,180)\n",
    "        if (label == 6 or label == 9) and degree == 90:\n",
    "            while degree != 90:\n",
    "                degree = random.randint(1, 180)\n",
    "        rot_img = np.uint8(np.zeros(image.shape))\n",
    "        height, width = rot_img.shape\n",
    "        midx,midy = (width//2, height//2)\n",
    "        for i in range(rot_img.shape[0]):\n",
    "            for j in range(rot_img.shape[1]):\n",
    "                x= (i-midx)*np.cos(degree)+(j-midy)*np.sin(degree)\n",
    "                y= -(i-midx)*np.sin(degree)+(j-midy)*np.cos(degree)\n",
    "                x=round(x)+midx\n",
    "                y=round(y)+midy\n",
    "                if (x>=0 and y>=0 and x<image.shape[0] and  y<image.shape[1]):\n",
    "                    rot_img[i,j] = image[x,y]\n",
    "        return rot_img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:54:02.759697427Z",
     "start_time": "2023-05-15T17:54:02.737406221Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [],
   "source": [
    "def noise(im):\n",
    "    noize = np.zeros(im.shape,np.uint8)\n",
    "    cv2.randn(noize,0,50)\n",
    "    n_im = cv2.add(im,noize)\n",
    "    return n_im"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:54:03.315163790Z",
     "start_time": "2023-05-15T17:54:03.003591626Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [],
   "source": [
    "def normalize(im):\n",
    "    imin = float(im.min())\n",
    "    imax = float(im.max())\n",
    "    return (im - imin)/(imax - imin)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:54:03.473006418Z",
     "start_time": "2023-05-15T17:54:03.268773099Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [],
   "source": [
    "def conf(pred, target):\n",
    "    confusion_vector = pred/target\n",
    "    tp = torch.sum(confusion_vector==1).item()\n",
    "    fp = torch.sum(confusion_vector == float('inf')).item()\n",
    "    tn = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    fn = torch.sum(confusion_vector == 0).item()\n",
    "    return tp,fp,tn,fn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:54:03.764794017Z",
     "start_time": "2023-05-15T17:54:03.455355379Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [],
   "source": [
    "def saveModel(x):\n",
    "    path = './' + x + '.pth'\n",
    "    torch.save(net.state_dict(),path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:54:03.891818601Z",
     "start_time": "2023-05-15T17:54:03.655254302Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [59800/60000 (100%)]\tLoss: 0.286823\n",
      "Train Epoch: 1 [59800/60000 (100%)]\tLoss: 0.188629\n",
      "Train Epoch: 2 [59800/60000 (100%)]\tLoss: 0.430721\n",
      "Train Epoch: 3 [59800/60000 (100%)]\tLoss: 0.260270\n",
      "Train Epoch: 4 [59800/60000 (100%)]\tLoss: 0.202833\n",
      "Train Epoch: 5 [59800/60000 (100%)]\tLoss: 0.194696\n",
      "Train Epoch: 6 [59800/60000 (100%)]\tLoss: 0.140471\n",
      "Train Epoch: 7 [59800/60000 (100%)]\tLoss: 0.151312\n",
      "tensor(0.1856)\n"
     ]
    }
   ],
   "source": [
    "average_loss = 0.0\n",
    "for epoch in range(epochs - 2):\n",
    "    for i in range(len(images) // batch_size):\n",
    "        batch = batch_size * i\n",
    "        i_batch = images[batch:batch + batch_size]\n",
    "        l_batch = labels[batch:batch + batch_size]\n",
    "        for j in range(len(i_batch)):\n",
    "            i_batch[j] = noise(i_batch[j])\n",
    "            # i_batch[j] = rotate(i_batch[j], l_batch[j])\n",
    "        data = torch.from_numpy(normalize(i_batch)).float()\n",
    "        target = torch.from_numpy(l_batch)\n",
    "        data = data.unsqueeze(1)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        net_out = net(data)\n",
    "        loss = criterion(net_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, i * len(data), len(images),\n",
    "               100. * batch / len(images), loss.data))\n",
    "    average_loss += loss.data\n",
    "average_loss = average_loss / epochs\n",
    "print(average_loss)\n",
    "saveModel(str(float(average_loss)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:56:33.689971670Z",
     "start_time": "2023-05-15T17:54:03.863888539Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [],
   "source": [
    "norm_test_values = normalize(test_images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:56:46.579645652Z",
     "start_time": "2023-05-15T17:56:46.509195292Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7307/2749422895.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(im_batch, volatile=True), Variable(lb_batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 8860/10000 (89%)\n",
      "\n",
      "Precision 0.9804  Recall 0.9978  F1 0.9890 \n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "tp= fp = tn = fn = 0\n",
    "for i in range(len(norm_test_values)//batch_size):\n",
    "    batch = batch_size * i\n",
    "    im_batch = torch.from_numpy(norm_test_values[batch:batch + batch_size]).float()\n",
    "    lb_batch = torch.from_numpy(test_labels[batch:batch + batch_size])\n",
    "    data, target = Variable(im_batch, volatile=True), Variable(lb_batch)\n",
    "    data = data.unsqueeze(1)\n",
    "    net_out = net(data)\n",
    "    test_loss += criterion(net_out, target).data\n",
    "    pred = net_out.data.max(1)[1]\n",
    "    correct += pred.eq(target.data).sum()\n",
    "    tp1,fp1,tn1,fn1 = conf(pred,target.data)\n",
    "    tp += tp1\n",
    "    fp += fp1\n",
    "    tn += tn1\n",
    "    fn += fn1\n",
    "test_loss /= len(test_images)\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1 = 2*precision * recall/(precision + recall)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_images),\n",
    "    100. * correct / len(test_images)))\n",
    "print(\"Precision %.4f \"%precision,'Recall %.4f '%recall, \"F1 %.4f \"%f1 )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T17:56:48.053779404Z",
     "start_time": "2023-05-15T17:56:46.920512628Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:04:50.671689931Z",
     "start_time": "2023-05-09T17:04:50.629134086Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
