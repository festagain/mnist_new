{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "output_path = \"mnist_train_images/\"\n",
    "train_path = \"mnist_train.csv\"\n",
    "test_path = \"mnist_test.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:48:20.172711369Z",
     "start_time": "2023-05-09T16:48:20.153124860Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "def convert_dataset(train_path):\n",
    "    dataset = np.genfromtxt(train_path, delimiter=',',skip_header=1)\n",
    "    labels = dataset[:, 0].astype(np.uint8)\n",
    "    values = dataset[:,1:].astype(np.uint8)\n",
    "    images = np.reshape(values, (-1,28,28))\n",
    "    return images,labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:48:16.243772181Z",
     "start_time": "2023-05-09T16:48:16.219738167Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T16:48:47.700466406Z",
     "start_time": "2023-05-09T16:48:26.052112493Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = np.genfromtxt(\"mnist_train.csv\", delimiter=',', skip_header=1)\n",
    "# labels = dataset[:, 0].astype(np.uint8)\n",
    "# values = dataset[:,1:].astype(np.uint8)\n",
    "# images = np.reshape(values, (-1,28,28))\n",
    "# images.shape\n",
    "\n",
    "images, labels = convert_dataset(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T16:49:44.448380793Z",
     "start_time": "2023-05-09T16:49:41.461879210Z"
    }
   },
   "outputs": [],
   "source": [
    "test_images, test_labels = convert_dataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 200\n",
    "epochs = 10\n",
    "log_interval = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:49:45.767794998Z",
     "start_time": "2023-05-09T16:49:45.754072415Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:49:46.158021721Z",
     "start_time": "2023-05-09T16:49:46.133073053Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.fc3 = nn.Linear(200, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:49:46.513644269Z",
     "start_time": "2023-05-09T16:49:46.476223537Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "Net(\n  (fc1): Linear(in_features=784, out_features=200, bias=True)\n  (fc2): Linear(in_features=200, out_features=200, bias=True)\n  (fc3): Linear(in_features=200, out_features=10, bias=True)\n)"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:49:46.959031010Z",
     "start_time": "2023-05-09T16:49:46.923799639Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum=0.9)\n",
    "criterion = nn.NLLLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:49:47.381320604Z",
     "start_time": "2023-05-09T16:49:47.373703333Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "def rotate(image, label):\n",
    "        degree = random.randint(1,180)\n",
    "        if (label == 6 or label == 9) and degree == 90:\n",
    "            while degree != 90:\n",
    "                degree = random.randint(1, 180)\n",
    "        rot_img = np.uint8(np.zeros(image.shape))\n",
    "        height, width = rot_img.shape\n",
    "        midx,midy = (width//2, height//2)\n",
    "        for i in range(rot_img.shape[0]):\n",
    "            for j in range(rot_img.shape[1]):\n",
    "                x= (i-midx)*np.cos(degree)+(j-midy)*np.sin(degree)\n",
    "                y= -(i-midx)*np.sin(degree)+(j-midy)*np.cos(degree)\n",
    "                x=round(x)+midx\n",
    "                y=round(y)+midy\n",
    "                if (x>=0 and y>=0 and x<image.shape[0] and  y<image.shape[1]):\n",
    "                    rot_img[i,j] = image[x,y]\n",
    "        return rot_img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:49:47.816150457Z",
     "start_time": "2023-05-09T16:49:47.809540432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "def noise(im):\n",
    "    noize = np.zeros(im.shape,np.uint8)\n",
    "    cv2.randn(noize,0,50)\n",
    "    n_im = cv2.add(im,noize)\n",
    "    return n_im"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:49:48.261409247Z",
     "start_time": "2023-05-09T16:49:48.258501481Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "def normalize(im):\n",
    "    imin = float(im.min())\n",
    "    imax = float(im.max())\n",
    "    return (im - imin)/(imax - imin)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:49:48.648055944Z",
     "start_time": "2023-05-09T16:49:48.645241832Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "def conf(pred, target):\n",
    "    confusion_vector = pred/target\n",
    "    tp = torch.sum(confusion_vector==1).item()\n",
    "    fp = torch.sum(confusion_vector == float('inf')).item()\n",
    "    tn = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    fn = torch.sum(confusion_vector == 0).item()\n",
    "    return tp,fp,tn,fn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:49:49.044734226Z",
     "start_time": "2023-05-09T16:49:49.036941954Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "def saveModel():\n",
    "    path = './net.pth'\n",
    "    torch.save(net.state_dict(),path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:49:49.407217816Z",
     "start_time": "2023-05-09T16:49:49.392659298Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/3114604308.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 4.392570\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_7409/977996670.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m             \u001B[0mi_batch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnoise\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi_batch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m             \u001B[0mi_batch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrotate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi_batch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ml_batch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m         \u001B[0mim_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0mlb_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ml_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_7409/1198619669.py\u001B[0m in \u001B[0;36mrotate\u001B[0;34m(image, label)\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrot_img\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrot_img\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m                 \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mmidx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcos\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdegree\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mmidy\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdegree\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m                 \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mmidx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdegree\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mmidy\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcos\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdegree\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m                 \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mmidx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(len(images) // batch_size):\n",
    "        batch = batch_size * i\n",
    "        i_batch = images[batch:batch + batch_size]\n",
    "        l_batch = labels[batch:batch + batch_size]\n",
    "        for j in range(len(i_batch)):\n",
    "            i_batch[j] = noise(i_batch[j])\n",
    "            # i_batch[j] = rotate(i_batch[j], l_batch[j])\n",
    "        im_batch = torch.from_numpy(normalize(i_batch)).float()\n",
    "        lb_batch = torch.from_numpy(l_batch)\n",
    "\n",
    "        data, target = Variable(im_batch), Variable(lb_batch)\n",
    "        data = data.view(-1,28*28)\n",
    "        optimizer.zero_grad()\n",
    "        net_out = net(data)\n",
    "        loss = criterion(net_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(data), len(images),\n",
    "                       100. * batch / len(images), loss.data))\n",
    "    saveModel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:00:27.599386Z",
     "start_time": "2023-05-09T17:00:18.713946532Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "norm_test_values = normalize(test_images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:50:22.354600682Z",
     "start_time": "2023-05-09T16:50:22.307704217Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 9197/10000 (92%)\n",
      "\n",
      "Precision 0.9978  Recall 0.9897  F1 0.9937 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/1079460992.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(im_batch, volatile=True), Variable(lb_batch)\n",
      "/tmp/ipykernel_7409/3114604308.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "tp= fp = tn = fn = 0\n",
    "for i in range(len(norm_test_values)//batch_size):\n",
    "    batch = batch_size * i\n",
    "    im_batch = torch.from_numpy(norm_test_values[batch:batch + batch_size]).float()\n",
    "    lb_batch = torch.from_numpy(test_labels[batch:batch + batch_size])\n",
    "    data, target = Variable(im_batch, volatile=True), Variable(lb_batch)\n",
    "    data = data.view(-1,28*28)\n",
    "    net_out = net(data)\n",
    "    test_loss += criterion(net_out, target).data\n",
    "    pred = net_out.data.max(1)[1]\n",
    "    correct += pred.eq(target.data).sum()\n",
    "    tp1,fp1,tn1,fn1 = conf(pred,target.data)\n",
    "    tp += tp1\n",
    "    fp += fp1\n",
    "    tn += tn1\n",
    "    fn += fn1\n",
    "test_loss /= len(test_images)\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1 = 2*precision * recall/(precision + recall)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_images),\n",
    "    100. * correct / len(test_images)))\n",
    "print(\"Precision %.4f \"%precision,'Recall %.4f '%recall, \"F1 %.4f \"%f1 )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:50:23.212444979Z",
     "start_time": "2023-05-09T16:50:23.156649471Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "def inference(path):\n",
    "    images1, labels1 = convert_dataset(path)\n",
    "    arr = []\n",
    "    norm_images = normalize(images1)\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(norm_images)//batch_size):\n",
    "            batch = i * batch\n",
    "            data = torch.from_numpy(norm_images[batch:batch + batch_size]).float()\n",
    "            data = data.view(-1,28*28)\n",
    "            output = net(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            arr.append(predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:59:37.004361039Z",
     "start_time": "2023-05-09T16:59:36.976034038Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
