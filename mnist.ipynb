{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "output_path = \"mnist_train_images/\"\n",
    "train_path = \"mnist_train.csv\"\n",
    "test_path = \"mnist_test.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:02:29.257319514Z",
     "start_time": "2023-05-09T17:02:29.255148304Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def convert_dataset(train_path):\n",
    "    dataset = np.genfromtxt(train_path, delimiter=',',skip_header=1)\n",
    "    labels = dataset[:, 0].astype(np.uint8)\n",
    "    values = dataset[:,1:].astype(np.uint8)\n",
    "    images = np.reshape(values, (-1,28,28))\n",
    "    return images,labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:02:30.014993991Z",
     "start_time": "2023-05-09T17:02:30.004399318Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T17:02:52.841031525Z",
     "start_time": "2023-05-09T17:02:31.006008693Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = np.genfromtxt(\"mnist_train.csv\", delimiter=',', skip_header=1)\n",
    "# labels = dataset[:, 0].astype(np.uint8)\n",
    "# values = dataset[:,1:].astype(np.uint8)\n",
    "# images = np.reshape(values, (-1,28,28))\n",
    "# images.shape\n",
    "\n",
    "images, labels = convert_dataset(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:16.813756569Z",
     "start_time": "2023-05-09T17:03:13.463798412Z"
    }
   },
   "outputs": [],
   "source": [
    "test_images, test_labels = convert_dataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 200\n",
    "epochs = 10\n",
    "log_interval = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:27.041941341Z",
     "start_time": "2023-05-09T17:03:27.015190763Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:27.584826009Z",
     "start_time": "2023-05-09T17:03:27.576567970Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.fc3 = nn.Linear(200, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:28.064622780Z",
     "start_time": "2023-05-09T17:03:28.055064178Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Net(\n  (fc1): Linear(in_features=784, out_features=200, bias=True)\n  (fc2): Linear(in_features=200, out_features=200, bias=True)\n  (fc3): Linear(in_features=200, out_features=10, bias=True)\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:28.470517091Z",
     "start_time": "2023-05-09T17:03:28.454815809Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum=0.9)\n",
    "criterion = nn.NLLLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:28.833927448Z",
     "start_time": "2023-05-09T17:03:28.830579395Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def rotate(image, label):\n",
    "        degree = random.randint(1,180)\n",
    "        if (label == 6 or label == 9) and degree == 90:\n",
    "            while degree != 90:\n",
    "                degree = random.randint(1, 180)\n",
    "        rot_img = np.uint8(np.zeros(image.shape))\n",
    "        height, width = rot_img.shape\n",
    "        midx,midy = (width//2, height//2)\n",
    "        for i in range(rot_img.shape[0]):\n",
    "            for j in range(rot_img.shape[1]):\n",
    "                x= (i-midx)*np.cos(degree)+(j-midy)*np.sin(degree)\n",
    "                y= -(i-midx)*np.sin(degree)+(j-midy)*np.cos(degree)\n",
    "                x=round(x)+midx\n",
    "                y=round(y)+midy\n",
    "                if (x>=0 and y>=0 and x<image.shape[0] and  y<image.shape[1]):\n",
    "                    rot_img[i,j] = image[x,y]\n",
    "        return rot_img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:29.250372504Z",
     "start_time": "2023-05-09T17:03:29.228074659Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def noise(im):\n",
    "    noize = np.zeros(im.shape,np.uint8)\n",
    "    cv2.randn(noize,0,50)\n",
    "    n_im = cv2.add(im,noize)\n",
    "    return n_im"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:29.636060084Z",
     "start_time": "2023-05-09T17:03:29.626436752Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def normalize(im):\n",
    "    imin = float(im.min())\n",
    "    imax = float(im.max())\n",
    "    return (im - imin)/(imax - imin)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:30.270156589Z",
     "start_time": "2023-05-09T17:03:30.261260270Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def conf(pred, target):\n",
    "    confusion_vector = pred/target\n",
    "    tp = torch.sum(confusion_vector==1).item()\n",
    "    fp = torch.sum(confusion_vector == float('inf')).item()\n",
    "    tn = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    fn = torch.sum(confusion_vector == 0).item()\n",
    "    return tp,fp,tn,fn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:30.671544177Z",
     "start_time": "2023-05-09T17:03:30.663830024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def saveModel():\n",
    "    path = './net.pth'\n",
    "    torch.save(net.state_dict(),path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:31.001150141Z",
     "start_time": "2023-05-09T17:03:30.994869154Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14760/3114604308.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.308064\n",
      "Train Epoch: 0 [2000/60000 (3%)]\tLoss: 2.288590\n",
      "Train Epoch: 0 [4000/60000 (7%)]\tLoss: 2.270425\n",
      "Train Epoch: 0 [6000/60000 (10%)]\tLoss: 2.220027\n",
      "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 2.159842\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 2.093765\n",
      "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 1.949393\n",
      "Train Epoch: 0 [14000/60000 (23%)]\tLoss: 1.756460\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 1.549798\n",
      "Train Epoch: 0 [18000/60000 (30%)]\tLoss: 1.192355\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.082516\n",
      "Train Epoch: 0 [22000/60000 (37%)]\tLoss: 0.881135\n",
      "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.676848\n",
      "Train Epoch: 0 [26000/60000 (43%)]\tLoss: 0.557882\n",
      "Train Epoch: 0 [28000/60000 (47%)]\tLoss: 0.535921\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 0.775524\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.630645\n",
      "Train Epoch: 0 [34000/60000 (57%)]\tLoss: 0.480651\n",
      "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.491313\n",
      "Train Epoch: 0 [38000/60000 (63%)]\tLoss: 0.453419\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.410170\n",
      "Train Epoch: 0 [42000/60000 (70%)]\tLoss: 0.476089\n",
      "Train Epoch: 0 [44000/60000 (73%)]\tLoss: 0.462348\n",
      "Train Epoch: 0 [46000/60000 (77%)]\tLoss: 0.472255\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.307256\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 0.410232\n",
      "Train Epoch: 0 [52000/60000 (87%)]\tLoss: 0.580589\n",
      "Train Epoch: 0 [54000/60000 (90%)]\tLoss: 0.506982\n",
      "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 0.265056\n",
      "Train Epoch: 0 [58000/60000 (97%)]\tLoss: 0.288698\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.462684\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.369614\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.426727\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.257881\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.312326\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.397140\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.376239\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.497022\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.394724\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.275507\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.463263\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.351476\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.313633\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.251608\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.286435\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.465119\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.444319\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.314636\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.385102\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.274239\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.296294\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.367416\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.335777\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.390805\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.226448\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.324316\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.500646\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.378771\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.206525\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.238667\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.374726\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.302714\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.379395\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.215886\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.276586\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.315566\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.333956\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.429476\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.345466\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.241706\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.415270\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.285690\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.280084\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.230387\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.273939\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.416860\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.398722\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.286818\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.336574\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.237659\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.284501\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.337935\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.315819\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.384595\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.214590\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.283328\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.459004\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.343184\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.183625\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.219460\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.355341\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.250326\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.330664\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.212933\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.278061\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.309212\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.321269\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.374187\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.337622\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.222360\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.380951\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.268483\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.259154\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.213120\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.273964\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.402169\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.352048\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.303985\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.318071\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.259285\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.261881\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.317529\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.334733\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.356390\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.245300\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.286254\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.414236\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.324511\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.181339\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.213554\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.356366\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.241101\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.326085\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.219904\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.276170\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.276658\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.312089\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.364862\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.353007\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.227599\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.403454\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.265433\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.249549\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.232014\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.249724\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.391098\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.302985\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.302798\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.333321\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.311331\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.273695\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.350914\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.395979\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.355399\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.252463\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.263620\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.377599\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.317490\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.203830\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.220322\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.349071\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.269645\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.332251\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.230840\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.276092\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.293091\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.390042\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.373577\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.352415\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.228753\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.380370\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.272535\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.268296\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.230539\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.248861\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.401399\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.271907\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.312878\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.339656\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.260923\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.266951\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.408520\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.450907\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.327375\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.288771\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.306579\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.389211\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.278561\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.228708\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.219514\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.326642\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.265987\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.344627\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.264129\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.317606\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.306386\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.537617\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.440754\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.431681\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.308092\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.399385\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.266157\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.262718\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.206895\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.252769\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.434918\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.305138\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.353921\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.335499\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.281964\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.281011\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.378422\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.389264\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.372243\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.421744\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.312411\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.446003\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.284583\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.250610\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.228788\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.371087\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.288964\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.305821\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.243830\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.384261\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.326861\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.588629\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.452060\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.462591\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.318456\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.427052\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.332476\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.306389\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.291907\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.243685\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.446560\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.371209\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.473692\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.377922\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.296671\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.297139\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.411401\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.369041\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.478480\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.518251\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.358179\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.503173\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.312327\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.285845\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.271104\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.481588\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.461599\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.408449\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.260835\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.453350\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.419329\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.480558\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.406574\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.590809\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.337353\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.469930\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.355119\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.453042\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.380514\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.372148\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.635241\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.563647\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.483533\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.428743\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.318491\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.331331\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.477466\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.513633\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.511033\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.466864\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.400895\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.535882\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.326501\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.322159\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.340998\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.503809\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.519422\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.440022\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.422613\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.558376\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.561106\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.563155\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.673517\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.704394\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.526432\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.699741\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.565678\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.740355\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.460813\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.528746\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.773155\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.817170\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.658681\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.647152\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.569609\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.543549\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.689882\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.616955\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.711624\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.438118\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.512022\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.705398\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.583303\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.464849\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.446449\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(len(images) // batch_size):\n",
    "        batch = batch_size * i\n",
    "        i_batch = images[batch:batch + batch_size]\n",
    "        l_batch = labels[batch:batch + batch_size]\n",
    "        for j in range(len(i_batch)):\n",
    "            i_batch[j] = noise(i_batch[j])\n",
    "            # i_batch[j] = rotate(i_batch[j], l_batch[j])\n",
    "        im_batch = torch.from_numpy(normalize(i_batch)).float()\n",
    "        lb_batch = torch.from_numpy(l_batch)\n",
    "\n",
    "        data, target = Variable(im_batch), Variable(lb_batch)\n",
    "        data = data.view(-1,28*28)\n",
    "        optimizer.zero_grad()\n",
    "        net_out = net(data)\n",
    "        loss = criterion(net_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(data), len(images),\n",
    "                       100. * batch / len(images), loss.data))\n",
    "    saveModel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:44.373859597Z",
     "start_time": "2023-05-09T17:03:32.427454979Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "norm_test_values = normalize(test_images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:49.939638671Z",
     "start_time": "2023-05-09T17:03:49.898684450Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 9239/10000 (92%)\n",
      "\n",
      "Precision 0.9980  Recall 0.9900  F1 0.9939 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14760/1079460992.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(im_batch, volatile=True), Variable(lb_batch)\n",
      "/tmp/ipykernel_14760/3114604308.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "tp= fp = tn = fn = 0\n",
    "for i in range(len(norm_test_values)//batch_size):\n",
    "    batch = batch_size * i\n",
    "    im_batch = torch.from_numpy(norm_test_values[batch:batch + batch_size]).float()\n",
    "    lb_batch = torch.from_numpy(test_labels[batch:batch + batch_size])\n",
    "    data, target = Variable(im_batch, volatile=True), Variable(lb_batch)\n",
    "    data = data.view(-1,28*28)\n",
    "    net_out = net(data)\n",
    "    test_loss += criterion(net_out, target).data\n",
    "    pred = net_out.data.max(1)[1]\n",
    "    correct += pred.eq(target.data).sum()\n",
    "    tp1,fp1,tn1,fn1 = conf(pred,target.data)\n",
    "    tp += tp1\n",
    "    fp += fp1\n",
    "    tn += tn1\n",
    "    fn += fn1\n",
    "test_loss /= len(test_images)\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1 = 2*precision * recall/(precision + recall)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_images),\n",
    "    100. * correct / len(test_images)))\n",
    "print(\"Precision %.4f \"%precision,'Recall %.4f '%recall, \"F1 %.4f \"%f1 )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:03:50.970788874Z",
     "start_time": "2023-05-09T17:03:50.928500396Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def inference(path):\n",
    "    images1, labels1 = convert_dataset(path)\n",
    "    arr = []\n",
    "    norm_images = normalize(images1)\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(norm_images)//batch_size):\n",
    "            batch = i * batch\n",
    "            data = torch.from_numpy(norm_images[batch:batch + batch_size]).float()\n",
    "            data = data.view(-1,28*28)\n",
    "            output = net(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            arr.append(predicted)\n",
    "    return arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:04:50.671689931Z",
     "start_time": "2023-05-09T17:04:50.629134086Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
